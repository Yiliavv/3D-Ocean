{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('B://workspace/tensorflow/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba8f4522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type        | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | transformer       | Transformer | 29.4 M | train\n",
      "1 | input_projection  | Linear      | 410 K  | train\n",
      "2 | output_projection | Linear      | 410 K  | train\n",
      "----------------------------------------------------------\n",
      "30.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "30.2 M    Total params\n",
      "120.944   Total estimated model params size (MB)\n",
      "57        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\workspace\\tensorflow\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b:\\workspace\\tensorflow\\.venv\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 358/358 [00:25<00:00, 13.89it/s, v_num=242, train_loss=0.547]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 358/358 [00:25<00:00, 13.88it/s, v_num=242, train_loss=0.547]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type        | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | transformer       | Transformer | 29.4 M | train\n",
      "1 | input_projection  | Linear      | 410 K  | train\n",
      "2 | output_projection | Linear      | 410 K  | train\n",
      "----------------------------------------------------------\n",
      "30.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "30.2 M    Total params\n",
      "120.944   Total estimated model params size (MB)\n",
      "57        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 358/358 [00:25<00:00, 13.79it/s, v_num=243, train_loss=1.310]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 358/358 [00:25<00:00, 13.79it/s, v_num=243, train_loss=1.310]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type        | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | transformer       | Transformer | 29.4 M | train\n",
      "1 | input_projection  | Linear      | 410 K  | train\n",
      "2 | output_projection | Linear      | 410 K  | train\n",
      "----------------------------------------------------------\n",
      "30.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "30.2 M    Total params\n",
      "120.944   Total estimated model params size (MB)\n",
      "57        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 358/358 [00:25<00:00, 13.87it/s, v_num=244, train_loss=0.385]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 358/358 [00:25<00:00, 13.87it/s, v_num=244, train_loss=0.385]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type        | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | transformer       | Transformer | 29.4 M | train\n",
      "1 | input_projection  | Linear      | 410 K  | train\n",
      "2 | output_projection | Linear      | 410 K  | train\n",
      "----------------------------------------------------------\n",
      "30.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "30.2 M    Total params\n",
      "120.944   Total estimated model params size (MB)\n",
      "57        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 358/358 [00:25<00:00, 14.15it/s, v_num=245, train_loss=0.608]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 358/358 [00:25<00:00, 14.15it/s, v_num=245, train_loss=0.608]\n"
     ]
    }
   ],
   "source": [
    "# 训练 Transformer 模型\n",
    "import numpy as np\n",
    "import torch\n",
    "from src.trainer.transformer import train_transformer_models\n",
    "\n",
    "sst_models = train_transformer_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0481493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config.params import Areas, MODEL_SAVE_PATH\n",
    "\n",
    "# 保存模型\n",
    "for model, area in zip(sst_models, Areas):\n",
    "    torch.save(model, f\"{MODEL_SAVE_PATH}/sst_model_{area.title}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "537d766d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 训练 DF 模型\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_rf_model\n\u001b[0;32m      5\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m train_rf_model()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 训练 DF 模型\n",
    "import joblib\n",
    "from src.trainer.rf import train_rf_model\n",
    "\n",
    "rf_model = train_rf_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf364f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparams\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Areas, MODEL_SAVE_PATH\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 保存模型\u001b[39;00m\n\u001b[0;32m      4\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(rf_model, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_SAVE_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/rf_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.config.params import Areas, MODEL_SAVE_PATH\n",
    "\n",
    "# 保存模型\n",
    "joblib.dump(rf_model, f\"{MODEL_SAVE_PATH}/rf_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
