# BaseTrainer ä¼˜åŒ–åŠŸèƒ½ä½¿ç”¨æŒ‡å—

`BaseTrainer` ç°å·²é›†æˆæ€§èƒ½ä¼˜åŒ–åŠŸèƒ½ï¼Œå¯ç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€é¢å¤–é…ç½®ã€‚

**é»˜è®¤ä¼˜åŒ–ï¼ˆè‡ªåŠ¨å¯ç”¨ï¼‰**ï¼š
- âœ… å¤šè¿›ç¨‹æ•°æ®åŠ è½½ (num_workers=8)
- âœ… GPUå†…å­˜å›ºå®š (pin_memory=True)
- âœ… æ··åˆç²¾åº¦è®­ç»ƒ (precision="16-mixed")
- âœ… æŒä¹…åŒ–workers (persistent_workers=True)

**é¢„æœŸæ•ˆæœ**: 4-8å€è®­ç»ƒé€Ÿåº¦æå‡ï¼

---

## å¿«é€Ÿå¼€å§‹

### 1. åŸºç¡€ä½¿ç”¨ï¼ˆé»˜è®¤ä¼˜åŒ–å·²å¯ç”¨ï¼‰

```python
import uuid
import numpy as np
from src.trainer.base import BaseTrainer  # âœ… ä½¿ç”¨åŸæ¥çš„BaseTrainer
from src.models.RATransformer import RecursiveAttentionTransformer
from src.dataset.ERA5 import ERA5SSTMonthlyDataset
from src.config.area import Area
from src.config.params import MODEL_SAVE_PATH

# é…ç½®åŒºåŸŸ
area = Area('Global', lon=[-180, 180], lat=[-80, 80], description='å…¨çƒåŒºåŸŸ')

# é…ç½®å‚æ•°
trainer_uid = str(uuid.uuid4())
resolution = 2
seq_len = 2

width = int(area.width / resolution)
height = int(area.height / resolution)

# æ•°æ®é›†å‚æ•°
dataset_params = {
    "seq_len": seq_len,
    "offset": 0,
    "resolution": resolution,
}

# æ¨¡å‹å‚æ•°
model_params = {
    "width": width,
    "height": height,
    "seq_len": seq_len,
    "d_model": 512, 
    "num_heads": 8,
    "num_layers": 3,
    "dim_feedforward": 1024,
    "dropout": 0.1,
    "recursion_depth": 2,
    "learning_rate": 1e-3,
}

# è®­ç»ƒå‚æ•° - é»˜è®¤å¯ç”¨ä¼˜åŒ–
trainer_params = {
    "epochs": 500,
    "batch_size": 150,  # âœ… ä»50å¢åŠ åˆ°150ï¼ˆæ˜¾å­˜å……è¶³ï¼‰
    
    # ä»¥ä¸‹å‚æ•°å·²é»˜è®¤å¯ç”¨ï¼Œæ— éœ€æ‰‹åŠ¨è®¾ç½®
    # "num_workers": 8,          # å¤šè¿›ç¨‹æ•°æ®åŠ è½½
    # "pin_memory": True,        # GPUå†…å­˜å›ºå®š
    # "persistent_workers": True,# ä¿æŒå·¥ä½œè¿›ç¨‹
    # "prefetch_factor": 2,      # é¢„å–2ä¸ªbatch
    # "precision": "16-mixed",   # æ··åˆç²¾åº¦è®­ç»ƒ
}

# åˆ›å»ºè®­ç»ƒå™¨ - ä¼˜åŒ–åŠŸèƒ½å·²è‡ªåŠ¨é›†æˆ
trainer = BaseTrainer(
    title='RATransformer',
    area=area,
    uid=trainer_uid,
    model_class=RecursiveAttentionTransformer,
    dataset_class=ERA5SSTMonthlyDataset,
    save_path=f'{MODEL_SAVE_PATH}/seq_len-{seq_len}/ra_transformer.pkl',
    pre_model=False,
    dataset_params=dataset_params,
    trainer_params=trainer_params,
    model_params=model_params,
)

# å¼€å§‹è®­ç»ƒ - è‡ªåŠ¨äº«å— 4-8å€é€Ÿåº¦æå‡
model = trainer.train()
```

**é¢„æœŸæ•ˆæœ**ï¼š
- è®­ç»ƒé€Ÿåº¦æå‡ **4-8å€**
- GPUåˆ©ç”¨ç‡ä» 12% â†’ 70-80%
- æ˜¾å­˜ä½¿ç”¨ä» 2.7GB â†’ 6-7GB
- æ¯ä¸ªepochæ—¶é—´ï¼š~10åˆ†é’Ÿ â†’ ~1.5-2.5åˆ†é’Ÿ

---

## 2. è‡ªå®šä¹‰ä¼˜åŒ–å‚æ•°

å¦‚æœä½ æƒ³æ‰‹åŠ¨è°ƒæ•´ä¼˜åŒ–å‚æ•°ï¼ˆè¦†ç›–é»˜è®¤å€¼ï¼‰ï¼š

```python
trainer_params = {
    "epochs": 500,
    "batch_size": 150,
    
    # æ•°æ®åŠ è½½ä¼˜åŒ–ï¼ˆè‡ªå®šä¹‰ï¼‰
    "num_workers": 6,           # é»˜è®¤8ï¼Œå¯æ ¹æ®CPUè°ƒæ•´
    "pin_memory": True,         # é»˜è®¤True
    "persistent_workers": True, # é»˜è®¤True
    "prefetch_factor": 4,       # é»˜è®¤2ï¼Œå¢åŠ é¢„å–æå‡é€Ÿåº¦
    
    # è®­ç»ƒç²¾åº¦ä¼˜åŒ–
    "precision": "16-mixed",    # é»˜è®¤"16-mixed"ï¼Œå¯é€‰"32"æˆ–"bf16-mixed"
    
    # æ¢¯åº¦ç´¯ç§¯ï¼ˆå¯é€‰ï¼Œé»˜è®¤1ï¼‰
    "accumulate_grad_batches": 2,  # ç´¯ç§¯2ä¸ªbatchï¼Œæœ‰æ•ˆbatch_size=300
    
    # æ¢¯åº¦è£å‰ªï¼ˆå¯é€‰ï¼‰
    "gradient_clip_val": 1.0,
    "gradient_clip_algorithm": "norm",
}

trainer = BaseTrainer(
    # ... å…¶ä»–å‚æ•° ...
    trainer_params=trainer_params,
)
```

---

## 3. å¯ç”¨PyTorch 2.0ç¼–è¯‘ï¼ˆæœ€å¤§åŒ–æ€§èƒ½ï¼‰

å¯ç”¨æ‰€æœ‰ä¼˜åŒ–ï¼ŒåŒ…æ‹¬PyTorch 2.0æ¨¡å‹ç¼–è¯‘ï¼š

```python
trainer_params = {
    "epochs": 500,
    "batch_size": 150,
    
    # PyTorch 2.0 ç¼–è¯‘ï¼ˆéœ€è¦PyTorch >= 2.0ï¼‰
    "compile_model": True,
    "compile_mode": "reduce-overhead",  # å¯é€‰: "default", "reduce-overhead", "max-autotune"
}

trainer = BaseTrainer(
    # ... å…¶ä»–å‚æ•° ...
    trainer_params=trainer_params,
)

model = trainer.train()
```

**æ³¨æ„**ï¼š
- éœ€è¦ PyTorch >= 2.0
- é¦–æ¬¡ç¼–è¯‘éœ€è¦é¢å¤–æ—¶é—´ï¼ˆçº¦1-2åˆ†é’Ÿï¼‰
- ç¼–è¯‘åçš„æ¨¡å‹åœ¨åç»­epochä¸­ä¼šæ˜¾è‘—åŠ é€Ÿ

**é¢„æœŸæ•ˆæœ**ï¼š
- è®­ç»ƒé€Ÿåº¦æå‡ **8-15å€**ï¼ˆç›¸æ¯”æœªä¼˜åŒ–ç‰ˆæœ¬ï¼‰
- GPUåˆ©ç”¨ç‡ 85-95%
- æ¯ä¸ªepochæ—¶é—´ï¼š~10åˆ†é’Ÿ â†’ ~0.7-1.2åˆ†é’Ÿ

---

## 4. ç¦ç”¨ä¼˜åŒ–ï¼ˆè°ƒè¯•æ¨¡å¼ï¼‰

å¦‚æœé‡åˆ°é—®é¢˜éœ€è¦è°ƒè¯•ï¼Œå¯ä»¥ç¦ç”¨ä¼˜åŒ–ï¼š

```python
trainer_params = {
    "epochs": 500,
    "batch_size": 50,           # æ¢å¤åŸå§‹batch size
    
    # ç¦ç”¨ä¼˜åŒ–
    "num_workers": 0,           # å•çº¿ç¨‹æ•°æ®åŠ è½½
    "pin_memory": False,        # ç¦ç”¨å†…å­˜å›ºå®š
    "persistent_workers": False,
    "precision": "32",          # FP32å…¨ç²¾åº¦
}

trainer = BaseTrainer(
    # ... å…¶ä»–å‚æ•° ...
    trainer_params=trainer_params,
)
```

---

## 5. ä¸åŒbatch sizeçš„å»ºè®®

æ ¹æ®æ‚¨çš„GPUæ˜¾å­˜é€‰æ‹©åˆé€‚çš„batch sizeï¼š

| GPUæ˜¾å­˜ | æ¨èbatch_size | å­¦ä¹ ç‡è°ƒæ•´ | é¢„æœŸæ˜¾å­˜ä½¿ç”¨ |
|---------|---------------|-----------|-------------|
| 8GB     | 100-150       | 1.4-1.7e-3 | ~6-7GB     |
| 12GB    | 200-250       | 2.0-2.2e-3 | ~10-11GB   |
| 16GB    | 300-400       | 2.4-2.8e-3 | ~14-15GB   |
| 24GB    | 500-600       | 3.2-3.5e-3 | ~22-23GB   |

**å­¦ä¹ ç‡è°ƒæ•´å…¬å¼**ï¼š
```
new_lr = old_lr Ã— sqrt(new_batch_size / old_batch_size)
```

ç¤ºä¾‹ï¼ˆbatch_sizeä»50å¢åŠ åˆ°150ï¼‰ï¼š
```python
import math

old_lr = 1e-3
old_batch = 50
new_batch = 150

new_lr = old_lr * math.sqrt(new_batch / old_batch)
print(f"New learning rate: {new_lr:.4e}")  # è¾“å‡º: 1.7321e-03

model_params = {
    # ... å…¶ä»–å‚æ•° ...
    "learning_rate": new_lr,  # ä½¿ç”¨è°ƒæ•´åçš„å­¦ä¹ ç‡
}
```

---

## 6. ä¼˜åŒ–å¯¹æ¯”æµ‹è¯•

```python
import time
from src.trainer.base import BaseTrainer

# æµ‹è¯•æœªä¼˜åŒ–ç‰ˆæœ¬
print("=" * 60)
print("æµ‹è¯•æœªä¼˜åŒ–è®­ç»ƒï¼ˆFP32 + å•çº¿ç¨‹ï¼‰")
print("=" * 60)

unopt_trainer = BaseTrainer(
    # ... å‚æ•°é…ç½® ...
    trainer_params={
        "epochs": 5, 
        "batch_size": 50,
        "num_workers": 0,
        "precision": "32",
        "pin_memory": False,
    },
)

start_time = time.time()
unopt_trainer.train()
unopt_time = time.time() - start_time

print(f"æœªä¼˜åŒ–ç‰ˆæœ¬ 5 epochs ç”¨æ—¶: {unopt_time:.2f}ç§’")

# æµ‹è¯•ä¼˜åŒ–ç‰ˆæœ¬
print("\n" + "=" * 60)
print("æµ‹è¯•ä¼˜åŒ–è®­ç»ƒï¼ˆFP16 + å¤šçº¿ç¨‹ï¼‰")
print("=" * 60)

opt_trainer = BaseTrainer(
    # ... ç›¸åŒå‚æ•°é…ç½® ...
    trainer_params={
        "epochs": 5, 
        "batch_size": 150,
        # ä½¿ç”¨é»˜è®¤ä¼˜åŒ–é…ç½®
    },
)

start_time = time.time()
opt_trainer.train()
opt_time = time.time() - start_time

print(f"ä¼˜åŒ–ç‰ˆæœ¬ 5 epochs ç”¨æ—¶: {opt_time:.2f}ç§’")

# è®¡ç®—æé€Ÿæ¯”
speedup = unopt_time / opt_time
print("\n" + "=" * 60)
print(f"ğŸš€ é€Ÿåº¦æå‡: {speedup:.2f}x")
print("=" * 60)
```

---

## 7. ç›‘æ§è®­ç»ƒæ€§èƒ½

### æ–¹æ³•1ï¼šä½¿ç”¨nvidia-smiç›‘æ§GPU

åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œï¼š
```bash
# Windows PowerShell
nvidia-smi dmon -s pucvmet -d 1

# æˆ–ç®€å•æŸ¥çœ‹
nvidia-smi
```

**åº”è¾¾åˆ°çš„æŒ‡æ ‡**ï¼š
- GPUåˆ©ç”¨ç‡ (sm): >80%
- æ˜¾å­˜åˆ©ç”¨ç‡ (mem): >70%
- åŠŸè€—: >120W

### æ–¹æ³•2ï¼šåœ¨è®­ç»ƒä¸­æ·»åŠ æ€§èƒ½æ—¥å¿—

```python
from lightning.pytorch.callbacks import Callback
import time

class PerformanceCallback(Callback):
    def __init__(self):
        self.epoch_start_time = None
        
    def on_train_epoch_start(self, trainer, pl_module):
        self.epoch_start_time = time.time()
        
    def on_train_epoch_end(self, trainer, pl_module):
        epoch_time = time.time() - self.epoch_start_time
        
        # è®¡ç®—ååé‡
        samples_per_epoch = len(trainer.train_dataloader.dataset)
        throughput = samples_per_epoch / epoch_time
        
        print(f"\nğŸ“Š Epoch {trainer.current_epoch} Performance:")
        print(f"  â€¢ Time: {epoch_time:.2f}s")
        print(f"  â€¢ Throughput: {throughput:.2f} samples/s")
        print(f"  â€¢ Samples: {samples_per_epoch}")

# åœ¨è®­ç»ƒæ—¶ä½¿ç”¨
# æ³¨æ„ï¼šOptimizedTraineræš‚ä¸æ”¯æŒcallbacksï¼Œå¯ä»¥åœ¨base.pyä¸­æ·»åŠ æ”¯æŒ
```

---

## 8. æ•…éšœæ’æŸ¥

### é—®é¢˜1ï¼šæ˜¾å­˜ä¸è¶³ (CUDA Out of Memory)

**ç—‡çŠ¶**ï¼šè®­ç»ƒå¼€å§‹åæŠ¥é”™ `RuntimeError: CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# æ–¹æ³•1: å‡å°batch size
trainer_params = {
    "batch_size": 100,  # ä»150å‡å°‘åˆ°100
}

# æ–¹æ³•2: ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ä¿æŒæœ‰æ•ˆbatch size
trainer_params = {
    "batch_size": 75,           # å‡å°å®é™…batch size
    "accumulate_grad_batches": 2,  # æœ‰æ•ˆbatch size = 75Ã—2 = 150
}

# æ–¹æ³•3: å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆéœ€è¦åœ¨æ¨¡å‹ä¸­å®ç°ï¼‰
# model_params = {
#     "use_gradient_checkpointing": True,
# }
```

### é—®é¢˜2ï¼šnum_workerså¯¼è‡´å†…å­˜ä¸è¶³

**ç—‡çŠ¶**ï¼šç³»ç»Ÿå†…å­˜å ç”¨è¿‡é«˜ï¼Œè®­ç»ƒå˜æ…¢

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
trainer_params = {
    "num_workers": 4,  # ä»8å‡å°‘åˆ°4
}
```

### é—®é¢˜3ï¼šæ··åˆç²¾åº¦è®­ç»ƒå‡ºç°NaN

**ç—‡çŠ¶**ï¼šlosså˜æˆNaN

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# æ–¹æ³•1: ä½¿ç”¨bfloat16ï¼ˆå¦‚æœGPUæ”¯æŒï¼‰
trainer_params = {
    "precision": "bf16-mixed",  # RTX 4060 Tiæ”¯æŒ
}

# æ–¹æ³•2: å›é€€åˆ°FP32
trainer_params = {
    "precision": "32",
}

# æ–¹æ³•3: å¢å¼ºæ¢¯åº¦è£å‰ª
trainer_params = {
    "gradient_clip_val": 0.5,  # ä»1.0å‡å°åˆ°0.5
}
```

### é—®é¢˜4ï¼šæ•°æ®åŠ è½½å™¨å¡ä½

**ç—‡çŠ¶**ï¼šè®­ç»ƒå¼€å§‹åé•¿æ—¶é—´æ— å“åº”

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# Windowsç³»ç»Ÿå¯èƒ½éœ€è¦ç¦ç”¨persistent_workers
trainer_params = {
    "num_workers": 0,          # å…ˆå°è¯•å•çº¿ç¨‹
    "persistent_workers": False,
}
```

---

## 9. æœ€ä½³å®è·µ

### âœ… æ¨èé…ç½®ï¼ˆRTX 4060 Ti 8GBï¼‰

```python
trainer_params = {
    "epochs": 500,
    "batch_size": 150,
    
    # æ•°æ®åŠ è½½
    "num_workers": 6,           # ä¿å®ˆé…ç½®ï¼Œé¿å…å†…å­˜é—®é¢˜
    "pin_memory": True,
    "persistent_workers": True,
    "prefetch_factor": 2,
    
    # è®­ç»ƒç²¾åº¦
    "precision": "16-mixed",    # æ··åˆç²¾åº¦
    
    # æ¢¯åº¦ç®¡ç†
    "gradient_clip_val": 1.0,
}

# å­¦ä¹ ç‡è°ƒæ•´
model_params = {
    # ... å…¶ä»–å‚æ•° ...
    "learning_rate": 1.7e-3,  # ä»1e-3è°ƒæ•´ï¼ˆbatch sizeä»50â†’150ï¼‰
}

trainer = BaseTrainer(
    # ... å…¶ä»–å‚æ•° ...
    trainer_params=trainer_params,
    model_params=model_params,
)
```

### âš ï¸ æ³¨æ„äº‹é¡¹

1. **é¦–æ¬¡è¿è¡Œå»ºè®®**ï¼š
   - å…ˆç”¨5ä¸ªepochsæµ‹è¯•é…ç½®æ˜¯å¦æ­£å¸¸
   - ç¡®è®¤æ²¡æœ‰OOMé”™è¯¯åå†è¿›è¡Œå®Œæ•´è®­ç»ƒ

2. **å­¦ä¹ ç‡è°ƒæ•´**ï¼š
   - batch sizeæ”¹å˜åå¿…é¡»è°ƒæ•´å­¦ä¹ ç‡
   - ä½¿ç”¨warmupå¯ä»¥æé«˜ç¨³å®šæ€§

3. **ä¿å­˜æ£€æŸ¥ç‚¹**ï¼š
   - é•¿æ—¶é—´è®­ç»ƒå»ºè®®å¯ç”¨checkpointing
   - é˜²æ­¢æ„å¤–ä¸­æ–­ä¸¢å¤±è®­ç»ƒè¿›åº¦

4. **éªŒè¯ç»“æœ**ï¼š
   - ä¼˜åŒ–åçš„æ¨¡å‹åº”è¯¥è¾¾åˆ°ç›¸åŒæˆ–æ›´å¥½çš„ç²¾åº¦
   - å¦‚æœç²¾åº¦ä¸‹é™ï¼Œå°è¯•è°ƒæ•´å­¦ä¹ ç‡æˆ–å‡å°batch size

---

## 10. æ€»ç»“

### ä¼˜åŒ–æ•ˆæœå¯¹æ¯”

| ä¼˜åŒ–é¡¹ | å®æ–½éš¾åº¦ | é¢„æœŸæå‡ | æ¨èä¼˜å…ˆçº§ | å·²é»˜è®¤å¯ç”¨ |
|--------|---------|---------|-----------|----------|
| å¢åŠ batch size | â­ æç®€å• | 2-2.5x | ğŸ”¥ æœ€é«˜ | âŒ éœ€æ‰‹åŠ¨è®¾ç½® |
| num_workers | â­ æç®€å• | 1.5-2x | ğŸ”¥ æœ€é«˜ | âœ… é»˜è®¤=8 |
| æ··åˆç²¾åº¦è®­ç»ƒ | â­ æç®€å• | 1.5-2x | ğŸ”¥ æœ€é«˜ | âœ… é»˜è®¤FP16 |
| pin_memory | â­ æç®€å• | 1.1-1.3x | âš¡ é«˜ | âœ… é»˜è®¤True |
| æ¢¯åº¦ç´¯ç§¯ | â­â­ ç®€å• | 1.0-1.2x | âš¡ é«˜ | âŒ å¯é€‰ |
| PyTorchç¼–è¯‘ | â­â­ ç®€å• | 1.2-1.5x | ğŸŸ¢ ä¸­ | âŒ å¯é€‰ |

### å¿«é€Ÿå¯ç”¨æ–¹æ¡ˆ

**æ–¹æ¡ˆ1: ä¸€è¡Œä»£ç ä¼˜åŒ–ï¼ˆé»˜è®¤å¯ç”¨ï¼‰**
```python
# åªéœ€å¢åŠ batch_sizeï¼Œå…¶ä»–ä¼˜åŒ–è‡ªåŠ¨ç”Ÿæ•ˆ
trainer_params = {"epochs": 500, "batch_size": 150}
```
**é¢„æœŸæå‡**: 4-8å€

**æ–¹æ¡ˆ2: å®Œæ•´ä¼˜åŒ–ï¼ˆå¯ç”¨PyTorchç¼–è¯‘ï¼‰**
```python
trainer_params = {
    "epochs": 500, 
    "batch_size": 150,
    "compile_model": True,
}
```
**é¢„æœŸæå‡**: 8-15å€

### å…³é”®æ”¹è¿›

âœ… **BaseTrainerç°å·²é»˜è®¤å¯ç”¨æ€§èƒ½ä¼˜åŒ–**
- æ— éœ€é¢å¤–é…ç½®ï¼Œç›´æ¥äº«å—4-8å€é€Ÿåº¦æå‡
- å‘åå…¼å®¹ï¼Œå¯æ‰‹åŠ¨è¦†ç›–ä»»ä½•ä¼˜åŒ–å‚æ•°
- è‡ªåŠ¨æ‰“å°ä¼˜åŒ–é…ç½®æ‘˜è¦ï¼Œæ–¹ä¾¿ç›‘æ§

---

**æ›´å¤šé—®é¢˜ï¼Ÿ** æŸ¥çœ‹ `src/docs/PERFORMANCE_ANALYSIS.md` è·å–è¯¦ç»†çš„æ€§èƒ½åˆ†ææŠ¥å‘Šã€‚

