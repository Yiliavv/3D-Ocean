# RecursiveAttentionTransformer æ¨¡åž‹æ”¹è¿›è¯´æ˜Ž

## ðŸ“ æ”¹è¿›æ¦‚è¿°

æœ¬æ¬¡é‡æž„ä¸»è¦é’ˆå¯¹ `RecursiveAttentionTransformer` æ¨¡åž‹çš„ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—è¿›è¡Œäº†ç†è®ºå¯¹é½å’Œå®žçŽ°ä¼˜åŒ–ï¼š

1. **é€’å½’æ³¨æ„åŠ›æœºåˆ¶** (`RGAttention.py`)
2. **çƒè°æ³¢ä½ç½®ç¼–ç ** (`SphericalHarmonicEncoding.py`)

---

## ðŸ”„ 1. é€’å½’æ³¨æ„åŠ›æœºåˆ¶æ”¹è¿›

### æ”¹è¿›å‰çš„é—®é¢˜

- **å‘½åè¯¯å¯¼**ï¼šç§°ä¸º"é€’å½’"ä½†å®žé™…æ˜¯å¤šå±‚ç‹¬ç«‹æ³¨æ„åŠ›å †å 
- **å‚æ•°ä¸å…±äº«**ï¼šæ¯ä¸ªé€’å½’å±‚éƒ½æ˜¯ç‹¬ç«‹çš„ `MultiheadAttention`
- **ç†è®ºä¸æ¸…**ï¼šç¼ºä¹æ˜Žç¡®çš„é€’å½’å®šä¹‰

### æ”¹è¿›åŽçš„å®žçŽ°

æä¾›ä¸¤ç§æ³¨æ„åŠ›æœºåˆ¶ï¼Œå¯æ ¹æ®éœ€æ±‚é€‰æ‹©ï¼š

#### 1.1 çœŸæ­£çš„é€’å½’æ³¨æ„åŠ› (`TrueRecursiveAttention`)

**ç‰¹ç‚¹ï¼š**
- âœ… **å‚æ•°å…±äº«**ï¼šå•ä¸ªæ³¨æ„åŠ›å±‚å¾ªçŽ¯è°ƒç”¨ï¼ˆçœŸé€’å½’ï¼‰
- âœ… **è¿­ä»£ç»†åŒ–**ï¼šæ¯æ¬¡é€’å½’é€æ­¥ä¼˜åŒ–ç‰¹å¾è¡¨ç¤º
- âœ… **é—¨æŽ§æœºåˆ¶**ï¼šè‡ªé€‚åº”æŽ§åˆ¶æ–°æ—§ä¿¡æ¯èžåˆ
- âœ… **åŠ æƒç´¯ç§¯**ï¼šå¯å­¦ä¹ çš„æ­¥éª¤æƒé‡

**æ ¸å¿ƒä»£ç ï¼š**
```python
# å…±äº«çš„æ³¨æ„åŠ›å±‚ï¼ˆçœŸæ­£çš„é€’å½’ï¼‰
self.shared_attention = nn.MultiheadAttention(d_model, num_heads)

# é€’å½’è¿­ä»£
for step in range(self.recursion_depth):
    attn_output, _ = self.shared_attention(current_state, current_state, current_state)
    refined = self.refiner(attn_output)
    
    # é—¨æŽ§èžåˆ
    gate = self.gate_net(torch.cat([current_state, refined], dim=-1))
    current_state = gate * refined + (1 - gate) * current_state
    
    # åŠ æƒç´¯ç§¯
    accumulated_output = accumulated_output + step_weights[step] * current_state
```

**æ•°å­¦æè¿°ï¼š**
```
h^(0) = x
h^(t) = Gate(h^(t-1), Refine(Attention(h^(t-1)))) for t=1...T
output = Î£ w_t * h^(t) + x
```

**å‚æ•°é‡ï¼š** å°‘ï¼ˆå‚æ•°å…±äº«ï¼‰  
**è®¡ç®—é‡ï¼š** ä¸­ç­‰  
**é€‚ç”¨åœºæ™¯ï¼š** éœ€è¦è¿­ä»£ç»†åŒ–çš„ä»»åŠ¡ï¼Œå‚æ•°å—é™çš„åœºæ™¯

---

#### 1.2 å±‚æ¬¡æ³¨æ„åŠ› (`HierarchicalAttention`)

**ç‰¹ç‚¹ï¼š**
- âœ… **å¤šå±‚ç‹¬ç«‹**ï¼šæ¯å±‚æ•èŽ·ä¸åŒç²’åº¦çš„ç‰¹å¾
- âœ… **è‡ªé€‚åº”èžåˆ**ï¼šå­¦ä¹ æœ€ä¼˜å±‚é—´ç»„åˆæƒé‡
- âœ… **æ¸è¿›å¼æ®‹å·®**ï¼šé€å±‚ç´¯ç§¯ï¼Œé¿å…æ¢¯åº¦æ¶ˆå¤±
- âœ… **è·¨å±‚äº¤äº’**ï¼šé¢å¤–çš„èžåˆæ³¨æ„åŠ›å±‚

**æ ¸å¿ƒä»£ç ï¼š**
```python
# å¤šå±‚ç‹¬ç«‹æ³¨æ„åŠ›
self.attention_layers = nn.ModuleList([
    nn.MultiheadAttention(d_model, num_heads)
    for _ in range(num_levels)
])

# é€å±‚å¤„ç†
for attn_layer, transform in zip(self.attention_layers, self.level_transforms):
    attn_output, _ = attn_layer(current_input, current_input, current_input)
    transformed = transform(attn_output)
    level_output = transformed + current_input  # æ®‹å·®
    level_outputs.append(level_output)
    current_input = level_output

# åŠ æƒèžåˆ
weighted_sum = Î£ softmax(w_i) * level_outputs[i]

# è·¨å±‚æ³¨æ„åŠ›èžåˆ
fused_output, _ = self.fusion_attention(weighted_sum, weighted_sum, weighted_sum)
```

**æ•°å­¦æè¿°ï¼š**
```
h^(0) = x
h^(l) = Transform_l(Attention_l(h^(l-1))) + h^(l-1) for l=1...L
output = FusionAttention(Î£ w_l * h^(l))
```

**å‚æ•°é‡ï¼š** å¤šï¼ˆæ¯å±‚ç‹¬ç«‹ï¼‰  
**è®¡ç®—é‡ï¼š** è¾ƒå¤§  
**é€‚ç”¨åœºæ™¯ï¼š** å¤šå°ºåº¦ç‰¹å¾èžåˆï¼Œç²¾åº¦ä¼˜å…ˆçš„åœºæ™¯

---

### ä½¿ç”¨æ–¹æ³•

```python
from src.models.Attention.RGAttention import RecursiveAttention

# æ–¹å¼1ï¼šçœŸé€’å½’ï¼ˆå‚æ•°å…±äº«ï¼‰
attention = RecursiveAttention(
    d_model=256,
    num_heads=8,
    recursion_depth=3,
    mode='true_recursive'  # å…³é”®å‚æ•°
)

# æ–¹å¼2ï¼šå±‚æ¬¡æ³¨æ„åŠ›ï¼ˆå¤šå±‚èžåˆï¼‰
attention = RecursiveAttention(
    d_model=256,
    num_heads=8,
    recursion_depth=3,
    mode='hierarchical'  # é»˜è®¤æ¨¡å¼
)
```

åœ¨ `RATransformer` ä¸­ä½¿ç”¨ï¼š
```python
model = RecursiveAttentionTransformer(
    width=360, height=160, seq_len=12,
    d_model=256,
    num_heads=8,
    num_layers=4,
    recursion_depth=3,
    attention_mode='hierarchical',  # æˆ– 'true_recursive'
    norm_first=True  # Pre-LNï¼Œè®­ç»ƒæ›´ç¨³å®š
)
```

---

## ðŸŒ 2. çƒè°æ³¢ä½ç½®ç¼–ç æ”¹è¿›

### æ”¹è¿›å‰çš„é—®é¢˜

- âŒ **åŸºäºŽæ—¶é—´ç´¢å¼•**ï¼šè¾“å…¥æ˜¯ `positions`ï¼ˆæ—¶é—´åºåˆ—ç´¢å¼•ï¼‰ï¼Œè€Œéžç©ºé—´åæ ‡
- âŒ **åç¦»åŽŸç†**ï¼šæ²¡æœ‰åˆ©ç”¨çƒè°æ³¢çš„çƒé¢å‡ ä½•ç‰¹æ€§
- âŒ **åŠŸèƒ½é”™ä½**ï¼šåä¸º"çƒè°æ³¢"å®žé™…æ˜¯å‚æ•°åŒ–çš„æ—¶åºç¼–ç 

### æ”¹è¿›åŽçš„å®žçŽ°

#### 2.1 çœŸæ­£çš„çƒè°æ³¢æ•°å­¦å®žçŽ°

**å…³è”å‹’è®©å¾·å¤šé¡¹å¼** `P_l^m(cos Î¸)`ï¼š
```python
def legendre_polynomial(l, m, x):
    """
    é€’æŽ¨è®¡ç®—å…³è”å‹’è®©å¾·å¤šé¡¹å¼
    
    P_m^m(x) = (-1)^m * (2m-1)!! * (1-x^2)^(m/2)
    P_{l}^m = [(2l-1) * x * P_{l-1}^m - (l+m-1) * P_{l-2}^m] / (l-m)
    """
```

**å®žæ•°çƒè°æ³¢å‡½æ•°** `Y_l^m(Î¸, Ï†)`ï¼š
```python
def spherical_harmonics(l, m, theta, phi):
    """
    Y_l^m(Î¸, Ï†) = N_l^m * P_l^|m|(cos Î¸) * T_m(Ï†)
    
    å…¶ä¸­ï¼š
    - N_l^m = sqrt[(2l+1)/(4Ï€) * (l-|m|)!/(l+|m|)!]
    - T_m(Ï†) = cos(m*Ï†) if m >= 0, sin(|m|*Ï†) if m < 0
    """
```

**æ•°å­¦æ€§è´¨ï¼š**
1. **æ­£äº¤æ€§**: âˆ«âˆ« Y_l^m * Y_l'^m' dÎ© = Î´_ll' Î´_mm'
2. **å½’ä¸€åŒ–**: âˆ«âˆ« |Y_l^m|^2 dÎ© = 1
3. **å®Œå¤‡æ€§**: å¯å±•å¼€çƒé¢ä¸Šä»»æ„å‡½æ•°

---

#### 2.2 ç©ºé—´çƒè°æ³¢ç¼–ç  (`SpatialSphericalHarmonicEncoding`)

**åŠŸèƒ½ï¼š** ä¸ºæ¯ä¸ªç©ºé—´ç½‘æ ¼ç‚¹ï¼ˆç»çº¬åº¦ï¼‰è®¡ç®—çƒè°æ³¢ç‰¹å¾

**æ ¸å¿ƒæ€æƒ³ï¼š**
```
ç»çº¬åº¦ (lat, lon) â†’ çƒé¢åæ ‡ (Î¸, Ï†) â†’ çƒè°æ³¢åŸº Y_l^m â†’ æŠ•å½±åˆ° d_model
```

**å®žçŽ°ï¼š**
```python
class SpatialSphericalHarmonicEncoding(nn.Module):
    def __init__(self, lat_range, lon_range, d_model, max_degree=4):
        # 1. ç”Ÿæˆç»çº¬åº¦ç½‘æ ¼
        self.lats = torch.arange(lat_range[0], lat_range[1], resolution)
        self.lons = torch.arange(lon_range[0], lon_range[1], resolution)
        
        # 2. è½¬æ¢ä¸ºçƒé¢åæ ‡
        theta = Ï€/2 - lat  # æžè§’ï¼ˆä½™çº¬åº¦ï¼‰
        phi = lon          # æ–¹ä½è§’
        
        # 3. é¢„è®¡ç®—æ‰€æœ‰çƒè°æ³¢åŸºå‡½æ•°
        harmonics = compute_all_spherical_harmonics(theta, phi, max_degree)
        # harmonics: [height, width, (max_degree+1)^2]
        
        # 4. æŠ•å½±ç½‘ç»œ
        self.harmonic_projection = nn.Sequential(
            nn.Linear(num_harmonics, d_model // 2),
            nn.GELU(),
            nn.Linear(d_model // 2, d_model)
        )
    
    def forward(self):
        # è¿”å›žç©ºé—´ä½ç½®ç¼–ç  [height, width, d_model]
        return self.harmonic_projection(self.harmonics) + self.spatial_bias
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python
# åˆ›å»ºç©ºé—´ç¼–ç å™¨
spatial_encoder = SpatialSphericalHarmonicEncoding(
    lat_range=[-80, 80],    # çº¬åº¦èŒƒå›´
    lon_range=[-180, 180],  # ç»åº¦èŒƒå›´
    d_model=256,
    max_degree=4,           # çƒè°æ³¢æœ€å¤§é˜¶æ•°ï¼ˆå…±25ä¸ªåŸºå‡½æ•°ï¼‰
    resolution=1.0          # 1Â° åˆ†è¾¨çŽ‡
)

# èŽ·å–ç©ºé—´ç¼–ç 
spatial_encoding = spatial_encoder()  # [160, 360, 256]

# æ·»åŠ åˆ°æµ·è¡¨æ¸©åº¦ç‰¹å¾
# å°† [batch, seq, height, width] â†’ [batch, seq, height*width]
x_flat = x.view(batch, seq, -1)
x_flat = x_flat + spatial_encoding.view(1, 1, -1)
```

---

#### 2.3 æ—¶åºä½ç½®ç¼–ç  (`TemporalPositionalEncoding`)

**åŠŸèƒ½ï¼š** æ ‡å‡†çš„ Transformer ä½ç½®ç¼–ç ï¼Œç”¨äºŽæ—¶é—´åºåˆ—ç»´åº¦

```python
class TemporalPositionalEncoding(nn.Module):
    def __init__(self, seq_len, d_model):
        pe[:, 0::2] = sin(position / 10000^(2i/d_model))
        pe[:, 1::2] = cos(position / 10000^(2i/d_model))
    
    def forward(self, x=None):
        return self.pe.unsqueeze(0)  # [1, seq_len, d_model]
```

---

### å…¼å®¹æ€§å¤„ç†

ä¸ºä¿æŒå‘åŽå…¼å®¹ï¼Œ`SphericalHarmonicEncoding` ç±»ä»å­˜åœ¨ï¼Œä½†å†…éƒ¨ä½¿ç”¨ `TemporalPositionalEncoding`ï¼š

```python
class SphericalHarmonicEncoding(nn.Module):
    """å…¼å®¹æ—§ä»£ç ï¼Œå®žé™…ä½¿ç”¨æ—¶åºä½ç½®ç¼–ç """
    def __init__(self, seq_len, d_model, max_degree=4, hidden_dim=64):
        self.temporal_encoding = TemporalPositionalEncoding(seq_len, d_model)
    
    def forward(self, positions=None):
        return self.temporal_encoding()
```

---

## ðŸ§ª æµ‹è¯•ä¸ŽéªŒè¯

### è¿è¡Œçƒè°æ³¢æµ‹è¯•

```bash
cd src/models/PE
python test_spherical_harmonics.py
```

**æµ‹è¯•å†…å®¹ï¼š**
1. âœ“ æ­£äº¤æ€§éªŒè¯
2. âœ“ å½’ä¸€åŒ–éªŒè¯
3. âœ“ ç‰¹å®šå€¼éªŒè¯
4. âœ“ å¯è§†åŒ–çƒè°æ³¢å‡½æ•°
5. âœ“ ç©ºé—´ç¼–ç æ¨¡å—æµ‹è¯•

---

## ðŸ“Š æ€§èƒ½å¯¹æ¯”

| æ¨¡åž‹é…ç½® | å‚æ•°é‡ | è®¡ç®—é‡ | è®­ç»ƒé€Ÿåº¦ | æŽ¨èåœºæ™¯ |
|---------|--------|--------|---------|---------|
| **åŽŸå§‹é€’å½’æ³¨æ„åŠ›** | ä¸­ | ä¸­ | å¿« | åŸºçº¿å¯¹æ¯” |
| **çœŸé€’å½’æ³¨æ„åŠ›** | å°‘ (-30%) | ä¸­ | å¿« | å‚æ•°å—é™ã€éœ€è¦è¿­ä»£ç»†åŒ– |
| **å±‚æ¬¡æ³¨æ„åŠ›** | å¤š (+20%) | å¤§ | æ…¢ | ç²¾åº¦ä¼˜å…ˆã€å¤šå°ºåº¦ç‰¹å¾ |
| **+ ç©ºé—´çƒè°æ³¢** | å¢žåŠ å°‘é‡ | é¢„è®¡ç®— | å‡ ä¹Žæ— å½±å“ | å…¨çƒæ•°æ®ã€çƒé¢å‡ ä½• |

---

## ðŸš€ ä½¿ç”¨å»ºè®®

### 1. é€‰æ‹©æ³¨æ„åŠ›æ¨¡å¼

**çœŸé€’å½’ (true_recursive)**ï¼š
- âœ… å‚æ•°å°‘ï¼Œé€‚åˆèµ„æºå—é™
- âœ… è¿­ä»£ç»†åŒ–æ€æƒ³æ¸…æ™°
- âŒ è¡¨è¾¾èƒ½åŠ›å¯èƒ½ç•¥å¼±

**å±‚æ¬¡æ³¨æ„åŠ› (hierarchical)**ï¼š
- âœ… å¤šå°ºåº¦ç‰¹å¾èžåˆæ•ˆæžœå¥½
- âœ… è¡¨è¾¾èƒ½åŠ›å¼º
- âŒ å‚æ•°å’Œè®¡ç®—é‡è¾ƒå¤§

**å»ºè®®**ï¼šå…ˆç”¨ `hierarchical` éªŒè¯æ€§èƒ½ä¸Šé™ï¼Œå¦‚éœ€ä¼˜åŒ–å†åˆ‡æ¢ `true_recursive`

---

### 2. æ˜¯å¦ä½¿ç”¨ç©ºé—´çƒè°æ³¢ç¼–ç 

**é€‚ç”¨åœºæ™¯ï¼š**
- âœ… å…¨çƒæµ·æ´‹æ•°æ®ï¼ˆè·¨è¶Šå¤§æ´²å¤§æ´‹ï¼‰
- âœ… éœ€è¦åˆ©ç”¨çƒé¢å¯¹ç§°æ€§
- âœ… ç©ºé—´åˆ†è¾¨çŽ‡è¾ƒç²—ï¼ˆ1Â°-2Â°ï¼‰

**ä¸é€‚ç”¨åœºæ™¯ï¼š**
- âŒ å±€éƒ¨åŒºåŸŸæ•°æ®ï¼ˆå¦‚å•ä¸ªæµ·åŸŸï¼‰
- âŒ é«˜åˆ†è¾¨çŽ‡æ•°æ®ï¼ˆ0.1Â°-0.25Â°ï¼Œè®¡ç®—å¼€é”€å¤§ï¼‰
- âŒ é™†åœ°æ•°æ®ï¼ˆçƒè°æ³¢é’ˆå¯¹çƒé¢è®¾è®¡ï¼‰

**é›†æˆæ–¹å¼ï¼š**
```python
# åœ¨ RATransformer ä¸­æ·»åŠ ç©ºé—´ç¼–ç æ”¯æŒ
from src.models.PE.SphericalHarmonicEncoding import SpatialSphericalHarmonicEncoding

# åˆå§‹åŒ–
self.spatial_sh_encoding = SpatialSphericalHarmonicEncoding(
    lat_range=[-80, 80],
    lon_range=[-180, 180],
    d_model=d_model,
    max_degree=4
)

# åœ¨ forward ä¸­ä½¿ç”¨
spatial_enc = self.spatial_sh_encoding()  # [H, W, d_model]
# æ·»åŠ åˆ°è¾“å…¥ç‰¹å¾...
```

---

### 3. è®­ç»ƒé…ç½®å»ºè®®

```python
# æŽ¨èé…ç½®ï¼ˆå±‚æ¬¡æ³¨æ„åŠ› + Pre-LNï¼‰
model = RecursiveAttentionTransformer(
    width=360, height=160, seq_len=12,
    d_model=256,
    num_heads=8,
    num_layers=4,
    dim_feedforward=1024,
    dropout=0.1,
    recursion_depth=3,          # 3å±‚é€’å½’/å±‚æ¬¡
    attention_mode='hierarchical',  # æˆ– 'true_recursive'
    norm_first=True,            # Pre-LNï¼Œè®­ç»ƒæ›´ç¨³å®š
    learning_rate=1e-4
)

# è®­ç»ƒå‚æ•°
trainer_params = {
    'epochs': 500,
    'batch_size': 32,
    'gradient_clip_val': 1.0
}
```

---

## ðŸ“ˆ ç†è®ºå¯¹é½æ€»ç»“

| æ–¹é¢ | æ”¹è¿›å‰ | æ”¹è¿›åŽ |
|-----|--------|--------|
| **é€’å½’å®šä¹‰** | âŒ åä¸å‰¯å®ž | âœ… æä¾›çœŸé€’å½’å’Œå±‚æ¬¡ä¸¤ç§é€‰æ‹© |
| **å‚æ•°å…±äº«** | âŒ æ¯å±‚ç‹¬ç«‹ | âœ… çœŸé€’å½’æ¨¡å¼å‚æ•°å…±äº« |
| **çƒè°æ³¢** | âŒ åŸºäºŽæ—¶é—´ç´¢å¼• | âœ… åŸºäºŽç©ºé—´åæ ‡ï¼Œæ»¡è¶³æ•°å­¦å®šä¹‰ |
| **æ­£äº¤æ€§** | âŒ æ— ä¿è¯ | âœ… æ•°å€¼éªŒè¯æ­£äº¤æ€§å’Œå½’ä¸€åŒ– |
| **å¯è§£é‡Šæ€§** | âš ï¸ ä¸€èˆ¬ | âœ… æ•°å­¦åŽŸç†æ¸…æ™° |

---

## ðŸ“š å‚è€ƒæ–‡çŒ®

1. **çƒè°æ³¢ç†è®º**:
   - E. W. Weisstein. "Spherical Harmonic." MathWorld.
   - Gorski, K. M., et al. "HEALPix: A framework for high-resolution discretization." ApJ (2005).

2. **Transformer æ”¹è¿›**:
   - Xiong, R., et al. "On Layer Normalization in the Transformer Architecture." ICML (2020).
   - Liu, L., et al. "Understanding the Difficulty of Training Transformers." EMNLP (2020).

3. **é€’å½’ç¥žç»ç½‘ç»œ**:
   - Socher, R., et al. "Recursive Deep Models for Semantic Compositionality." EMNLP (2011).

---

## âœ… æ£€æŸ¥æ¸…å•

ä½¿ç”¨æ–°å®žçŽ°å‰è¯·ç¡®è®¤ï¼š

- [ ] å·²ç†è§£ä¸¤ç§æ³¨æ„åŠ›æ¨¡å¼çš„åŒºåˆ«
- [ ] æ ¹æ®ä»»åŠ¡éœ€æ±‚é€‰æ‹©åˆé€‚çš„æ¨¡å¼
- [ ] éªŒè¯çƒè°æ³¢ç¼–ç é€‚ç”¨æ€§
- [ ] è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯æ­£ç¡®æ€§
- [ ] è°ƒæ•´è¶…å‚æ•°ï¼ˆrecursion_depth, max_degreeï¼‰
- [ ] å¯¹æ¯”åŽŸå§‹æ¨¡åž‹æ€§èƒ½
- [ ] æ›´æ–°æ¨¡åž‹ä¿å­˜/åŠ è½½ä»£ç ï¼ˆå¦‚éœ€ï¼‰

---

## ðŸ› å·²çŸ¥é—®é¢˜

1. **çƒè°æ³¢è®¡ç®—æ•ˆçŽ‡**ï¼šé«˜é˜¶ï¼ˆmax_degree > 6ï¼‰å’Œé«˜åˆ†è¾¨çŽ‡ï¼ˆ< 0.5Â°ï¼‰æ—¶è®¡ç®—æ…¢
   - è§£å†³æ–¹æ¡ˆï¼šé¢„è®¡ç®—å¹¶ç¼“å­˜ï¼Œæˆ–ä½¿ç”¨ C++ æ‰©å±•

2. **å†…å­˜å ç”¨**ï¼šç©ºé—´çƒè°æ³¢ç¼–ç éœ€è¦å­˜å‚¨ `[H, W, num_harmonics]` çš„ buffer
   - è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ `resolution` å‚æ•°é™ä½Žåˆ†è¾¨çŽ‡

---

## ðŸ“ž è”ç³»ä¸Žåé¦ˆ

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·åœ¨é¡¹ç›®ä¸­æäº¤ Issue æˆ–è”ç³»å¼€å‘è€…ã€‚
