import arrow
import torch
import numpy as np
import platform
import os
from torch import save, load
from lightning import Trainer
from lightning.pytorch.loggers import WandbLogger
from lightning.pytorch.callbacks import ModelCheckpoint
from torch.utils.data import DataLoader, Subset
import wandb

from src.plot.sst import plot_sst, plot_sst_diff, plot_2d_kernel_density, plot_nino

from src.config.area import Area
from src.config.params import WANDB_PROJECT, WANDB_ENTITY

class BaseTrainer:
    """
    è®­ç»ƒå™¨åŸºç±» - é›†æˆæ€§èƒ½ä¼˜åŒ–å’Œ Checkpoint æœºåˆ¶
    
    å‚æ•°:
        title: str, æ¨¡å‹åç§°
        uid: str, è®­ç»ƒå™¨å”¯ä¸€æ ‡è¯†
        area: Area, åŒºåŸŸ
        model_class: LightningModule, æ¨¡å‹ç±»
        save_path: str, ä¿å­˜è·¯å¾„
        checkpoint_path: str, checkpoint è·¯å¾„ (ç”¨äºæ¢å¤è®­ç»ƒ)
        dataset_params: dict, æ•°æ®é›†å‚æ•°
        trainer_params: dict, è®­ç»ƒå‚æ•°
        model_params: dict, æ¨¡å‹å‚æ•°
        use_checkpoint: bool, æ˜¯å¦ä½¿ç”¨ checkpoint æœºåˆ¶ (é»˜è®¤: True)
        use_wandb: bool, æ˜¯å¦ä½¿ç”¨ wandb æ—¥å¿— (é»˜è®¤: True)
        
    dataset_params:
        seq_len: int, åºåˆ—é•¿åº¦
        offset: int, åç§»é‡
        resolution: float, åˆ†è¾¨ç‡
        
    trainer_params:
        epochs: int, è®­ç»ƒè½®æ•°
        batch_size: int, æ‰¹é‡å¤§å°
        split_ratio: list, è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„åˆ†å‰²æ¯”ä¾‹
        
        # Checkpoint å‚æ•°
        save_top_k: int, ä¿å­˜æœ€å¥½çš„ k ä¸ªæ¨¡å‹ (é»˜è®¤: 3)
        monitor: str, ç›‘æ§çš„æŒ‡æ ‡ (é»˜è®¤: "val_loss")
        mode: str, ç›‘æ§æ¨¡å¼ (é»˜è®¤: "min")
        
        # æ€§èƒ½ä¼˜åŒ–å‚æ•°
        num_workers: int, æ•°æ®åŠ è½½å·¥ä½œè¿›ç¨‹æ•° (é»˜è®¤: 8, æ¨èCPUæ ¸å¿ƒæ•°/2)
        pin_memory: bool, æ˜¯å¦å›ºå®šGPUå†…å­˜ (é»˜è®¤: True)
        persistent_workers: bool, æ˜¯å¦ä¿æŒå·¥ä½œè¿›ç¨‹ (é»˜è®¤: True)
        prefetch_factor: int, é¢„å–å› å­ (é»˜è®¤: 2)
        precision: str, è®­ç»ƒç²¾åº¦ (é»˜è®¤: "16-mixed", å¯é€‰: "32", "bf16-mixed")
        accumulate_grad_batches: int, æ¢¯åº¦ç´¯ç§¯æ­¥æ•° (é»˜è®¤: 1)
        gradient_clip_val: float, æ¢¯åº¦è£å‰ªå€¼ (é»˜è®¤: None)
        compile_model: bool, æ˜¯å¦ç¼–è¯‘æ¨¡å‹-PyTorch2.0+ (é»˜è®¤: False)
        compile_mode: str, ç¼–è¯‘æ¨¡å¼ (é»˜è®¤: "default")
        
    ä½¿ç”¨ç¤ºä¾‹:
        # ç¬¬ä¸€æ¬¡è®­ç»ƒ
        trainer = BaseTrainer(
            title='SST_Model',
            uid='run_001',
            area=area,
            model_class=YourModel,
            dataset_class=YourDataset,
            save_path='out/models/model.pkl',
            trainer_params={'epochs': 100},
            use_checkpoint=True
        )
        model = trainer.train()
        
        # ä» checkpoint æ¢å¤å¹¶ç»§ç»­è®­ç»ƒ
        trainer = BaseTrainer(
            title='SST_Model',
            uid='run_002',
            area=area,
            model_class=YourModel,
            dataset_class=YourDataset,
            checkpoint_path='out/checkpoints/SST_Model/last.ckpt',  # åŠ è½½ checkpoint
            trainer_params={'epochs': 150},  # å¯ä»¥ä¿®æ”¹è¶…å‚æ•°
            use_checkpoint=True
        )
        model = trainer.train()

    """
    
    def __init__(self,
                 title: str,
                 uid: str,
                 area: Area,
                 model_class = None,
                 dataset_class = None,
                 save_path: str = None,
                 checkpoint_path: str = None,  # æ–°å¢ï¼šcheckpoint è·¯å¾„
                 pre_model: bool = False,  # ä¿ç•™å‘åå…¼å®¹
                 dataset_params: dict = {},
                 trainer_params: dict = {},
                 model_params: dict = {},
                 use_checkpoint: bool = True,  # æ–°å¢ï¼šæ˜¯å¦ä½¿ç”¨ checkpoint
                 use_wandb: bool = True):
        
        self.trainer_uid = uid

        self.title = title
        self.area = area
        
        # å·¥å‚ç±»å‹
        self.model_class = model_class
        self.dataset_class = dataset_class

        # å‚æ•°
        self.dataset_params = dataset_params
        self.trainer_params = trainer_params
        self.model_params = model_params
        
        # ä¿å­˜è·¯å¾„å’Œ checkpoint
        self.save_path = save_path
        self.checkpoint_path = checkpoint_path
        self.use_checkpoint = use_checkpoint
        
        # å‘åå…¼å®¹ï¼šæ”¯æŒæ—§çš„ pre_model å‚æ•°
        self.pre_model = pre_model
        if pre_model and save_path and not checkpoint_path:
            print("âš ï¸  æ£€æµ‹åˆ°ä½¿ç”¨æ—§çš„ pre_model å‚æ•°ï¼Œå»ºè®®ä½¿ç”¨ checkpoint_path å‚æ•°")
            self.model = load(self.save_path, weights_only=False)
            self.trained = True
        else:
            self.model = None
            self.trained = False
        
        # wandb é…ç½®
        self.use_wandb = use_wandb
        self.wandb_logger = None
        
        # checkpoint callback
        self.checkpoint_callback = None
    
    def split(self, dataset):
        split_ratio = self.trainer_params.get('split_ratio', [0.8, 0.2])
        batch_size = self.trainer_params.get('batch_size', 20)
        
        # è®¡ç®—è®­ç»ƒé›†å¤§å°ï¼ˆæŒ‰æ—¶é—´é¡ºåºæœ‰åºåˆ†å‰²ï¼‰
        total_size = len(dataset)
        train_size = int(total_size * split_ratio[0])
        
        # æŒ‰æ—¶é—´é¡ºåºåˆ†å‰²ï¼šå‰train_sizeä¸ªæ ·æœ¬ä½œä¸ºè®­ç»ƒé›†ï¼Œåval_sizeä¸ªæ ·æœ¬ä½œä¸ºéªŒè¯é›†
        train_indices = list(range(train_size))
        val_indices = list(range(train_size, total_size))
        
        train_set = Subset(dataset, train_indices)
        val_set = Subset(dataset, val_indices)
        
        # ä¼˜åŒ–çš„DataLoaderé…ç½®
        # Windowsç³»ç»Ÿä¸Šå¤šè¿›ç¨‹DataLoaderå¯èƒ½æœ‰é—®é¢˜ï¼Œé»˜è®¤ä½¿ç”¨å•è¿›ç¨‹
        is_windows = platform.system() == 'Windows'
        default_workers = 0 if is_windows else 8
        
        num_workers = self.trainer_params.get('num_workers', default_workers)
        pin_memory = self.trainer_params.get('pin_memory', True)
        persistent_workers = self.trainer_params.get('persistent_workers', True) and num_workers > 0
        prefetch_factor = self.trainer_params.get('prefetch_factor', 2)
        
        dataloader_kwargs = {
            'batch_size': batch_size,
            'shuffle': False,
            'num_workers': num_workers,
            'pin_memory': pin_memory,
        }
        
        if num_workers > 0:
            dataloader_kwargs['persistent_workers'] = persistent_workers
            if prefetch_factor:
                dataloader_kwargs['prefetch_factor'] = prefetch_factor
        
        train_loader = DataLoader(train_set, **dataloader_kwargs)
        
        # éªŒè¯é›†ä½¿ç”¨è¾ƒå°‘çš„workers
        val_dataloader_kwargs = dataloader_kwargs.copy()
        val_dataloader_kwargs['num_workers'] = max(1, num_workers // 2)
        val_loader = DataLoader(val_set, **val_dataloader_kwargs)
        
        return train_loader, val_loader
        
    def _create_checkpoint_callback(self):
        """åˆ›å»º checkpoint callback"""
        if not self.use_checkpoint:
            return None
        
        # checkpoint ä¿å­˜ç›®å½•
        checkpoint_dir = f'out/checkpoints/{self.title}'
        os.makedirs(checkpoint_dir, exist_ok=True)
        
        # é…ç½® checkpoint callback
        checkpoint_callback = ModelCheckpoint(
            dirpath=checkpoint_dir,
            filename='{epoch}-{val_loss:.4f}',
            monitor=self.trainer_params.get('monitor', 'val_loss'),
            mode=self.trainer_params.get('mode', 'min'),
            save_top_k=self.trainer_params.get('save_top_k', 3),
            save_last=True,  # ä¿å­˜æœ€åä¸€ä¸ª checkpoint
            verbose=True,
        )
        
        print(f"\nğŸ’¾ Checkpoint é…ç½®:")
        print(f"  â€¢ ä¿å­˜è·¯å¾„: {checkpoint_dir}")
        print(f"  â€¢ ç›‘æ§æŒ‡æ ‡: {checkpoint_callback.monitor}")
        print(f"  â€¢ ä¿å­˜æœ€ä¼˜: Top-{checkpoint_callback.save_top_k}")
        print(f"  â€¢ ä¿å­˜æœ€æ–°: True\n")
        
        return checkpoint_callback
    
    def train(self):
        lon = self.area.lon
        lat = self.area.lat
        
        # å¯ç”¨ Tensor Cores ä¼˜åŒ–ï¼ˆé€‚ç”¨äº RTX ç³»åˆ— GPUï¼‰
        if torch.cuda.is_available() and hasattr(torch, 'set_float32_matmul_precision'):
            matmul_precision = self.trainer_params.get('matmul_precision', 'high')
            torch.set_float32_matmul_precision(matmul_precision)
        
        dataset = self.dataset_class(
            lon=lon,
            lat=lat,
            **self.dataset_params
        )
        
        train_loader, val_loader = self.split(dataset)
        
        # åˆ¤æ–­æ˜¯å¦ä» checkpoint æ¢å¤
        resume_from_checkpoint = None
        if self.checkpoint_path and os.path.exists(self.checkpoint_path):
            resume_from_checkpoint = self.checkpoint_path
            print(f"\nğŸ”„ ä» checkpoint æ¢å¤è®­ç»ƒ: {self.checkpoint_path}\n")
        
        if not self.pre_model and not resume_from_checkpoint:
            # åˆ›å»ºæ–°æ¨¡å‹
            self.model = self.model_class(
                **self.model_params
            )
            
            # PyTorch 2.0+ æ¨¡å‹ç¼–è¯‘
            if self.trainer_params.get('compile_model', False):
                if hasattr(torch, 'compile'):
                    compile_mode = self.trainer_params.get('compile_mode', 'default')
                    print(f"ğŸš€ ç¼–è¯‘æ¨¡å‹ (æ¨¡å¼: {compile_mode})...")
                    self.model = torch.compile(self.model, mode=compile_mode)
                else:
                    print("âš ï¸  PyTorchç‰ˆæœ¬ < 2.0, æ¨¡å‹ç¼–è¯‘ä¸å¯ç”¨")
        elif resume_from_checkpoint:
            # ä» checkpoint åŠ è½½æ—¶ï¼Œå…ˆåˆ›å»ºæ¨¡å‹ç»“æ„
            self.model = self.model_class(
                **self.model_params
            )
            
            # å¦‚æœéœ€è¦ä¿®æ”¹å­¦ä¹ ç‡ç­‰è¶…å‚æ•°ï¼Œåœ¨è¿™é‡Œå¤„ç†
            # æ³¨æ„ï¼šè¿™äº›ä¿®æ”¹ä¼šåœ¨ checkpoint åŠ è½½åç”Ÿæ•ˆ
            if 'learning_rate' in self.model_params:
                print(f"âš™ï¸  è®¾ç½®æ–°çš„å­¦ä¹ ç‡: {self.model_params['learning_rate']}")
                self.model.learning_rate = self.model_params['learning_rate']
        
        epochs = self.trainer_params.get('epochs', 100)
        
        # åˆå§‹åŒ– wandb logger
        if self.use_wandb:
            self.wandb_logger = self._init_wandb_logger()
        
        # åˆ›å»º checkpoint callback
        self.checkpoint_callback = self._create_checkpoint_callback()
        
        # ä¼˜åŒ–çš„Traineré…ç½®
        trainer_config = {
            'max_epochs': epochs,
            'accelerator': 'gpu',
            'enable_checkpointing': self.use_checkpoint,
            'num_sanity_val_steps': 0,
            'precision': self.trainer_params.get('precision', '16-mixed'),
        }
        
        # æ·»åŠ  callbacks
        callbacks = []
        if self.checkpoint_callback:
            callbacks.append(self.checkpoint_callback)
        if callbacks:
            trainer_config['callbacks'] = callbacks
        
        # æ·»åŠ  wandb logger
        if self.wandb_logger:
            trainer_config['logger'] = self.wandb_logger
        
        # æ¢¯åº¦ç´¯ç§¯
        accumulate_grad_batches = self.trainer_params.get('accumulate_grad_batches', 1)
        if accumulate_grad_batches > 1:
            trainer_config['accumulate_grad_batches'] = accumulate_grad_batches
        
        # æ¢¯åº¦è£å‰ª
        gradient_clip_val = self.trainer_params.get('gradient_clip_val', None)
        if gradient_clip_val:
            trainer_config['gradient_clip_val'] = gradient_clip_val
            trainer_config['gradient_clip_algorithm'] = self.trainer_params.get(
                'gradient_clip_algorithm', 'norm'
            )

        trainer = Trainer(**trainer_config)
        
        # æ‰“å°ä¼˜åŒ–é…ç½®æ‘˜è¦
        self._print_optimization_summary(accumulate_grad_batches)
        
        start_time = arrow.Arrow.now().format('YYYY-MM-DD HH:mm:ss')
        print(f"================================================")
        print(f"Model: {self.model_class.__name__} Training Started at: {start_time}")

        import time
        train_start = time.time()
        
        # ä» checkpoint æ¢å¤è®­ç»ƒ
        if resume_from_checkpoint:
            trainer.fit(self.model, train_loader, val_loader, ckpt_path=resume_from_checkpoint)
        else:
            trainer.fit(self.model, train_loader, val_loader)
        
        train_time = time.time() - train_start
        
        end_time = arrow.Arrow.now().format('YYYY-MM-DD HH:mm:ss')
        print(f"Model: {self.model_class.__name__} Training Ended at: {end_time}")
        
        spend_time = arrow.get(end_time) - arrow.get(start_time)
        print(f"Model: {self.model_class.__name__} Training Duration: {spend_time}")
        
        # è®¡ç®—ååé‡
        total_samples = len(train_loader.dataset) * epochs
        throughput = total_samples / train_time if train_time > 0 else 0
        print(f"Training Throughput: {throughput:.2f} samples/second")
        print(f"================================================")

        # è®°å½•æœ€ç»ˆæŒ‡æ ‡åˆ° wandb
        if self.use_wandb and self.wandb_logger:
            self._log_final_metrics(train_time, throughput)

        self.trained = True

        if self.save_path:
            self.save()
            
            # ä¿å­˜æ¨¡å‹åˆ° wandb artifacts
            if self.use_wandb and self.wandb_logger:
                self._save_model_artifact()

        # å…³é—­ wandb run
        if self.use_wandb:
            wandb.finish()

        return self.model
    
    def _init_wandb_logger(self):
        """åˆå§‹åŒ– wandb logger"""
        try:
            # æ„å»ºé…ç½®å­—å…¸
            config = {
                'model': self.model_class.__name__,
                'dataset': self.dataset_class.__name__,
                'area': {
                    'lon': self.area.lon.tolist() if hasattr(self.area.lon, 'tolist') else self.area.lon,
                    'lat': self.area.lat.tolist() if hasattr(self.area.lat, 'tolist') else self.area.lat,
                    'title': self.area.title,
                },
                'model_params': self.model_params,
                'dataset_params': self.dataset_params,
                'trainer_params': self.trainer_params,
            }
            
            # è·å–æ¨¡å‹çš„æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨é…ç½®
            if self.model:
                optimizer_config = self._get_optimizer_config()
                if optimizer_config:
                    config['optimizer'] = optimizer_config
                
                loss_function_info = self._get_loss_function_info()
                if loss_function_info:
                    config['loss_function'] = loss_function_info
            
            # åˆ›å»º wandb logger
            logger = WandbLogger(
                project=WANDB_PROJECT,
                entity=WANDB_ENTITY,
                name=f"{self.title}_{self.model_class.__name__}",
                id=self.trainer_uid,
                config=config,
                save_dir='./out/wandb_logs',
            )
            
            print(f"\nğŸ“Š Wandb å·²å¯ç”¨")
            print(f"  â€¢ Project: {WANDB_PROJECT}")
            print(f"  â€¢ Run ID: {self.trainer_uid}")
            print(f"  â€¢ Run URL: {logger.experiment.url}\n")
            
            return logger
            
        except Exception as e:
            print(f"\nâš ï¸  Wandb åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            print(f"  è®­ç»ƒå°†ç»§ç»­ï¼Œä½†ä¸è®°å½•åˆ° wandb\n")
            return None
    
    def _get_optimizer_config(self):
        """è·å–ä¼˜åŒ–å™¨é…ç½®ä¿¡æ¯"""
        try:
            # Lightning æ¨¡å‹é€šè¿‡ configure_optimizers() è¿”å›ä¼˜åŒ–å™¨
            if hasattr(self.model, 'configure_optimizers'):
                optimizers_config = self.model.configure_optimizers()
                
                # å¤„ç†ä¸åŒçš„è¿”å›æ ¼å¼
                optimizer = None
                scheduler = None
                
                if isinstance(optimizers_config, tuple):
                    # è¿”å› (optimizer, scheduler) æˆ– ([optimizers], [schedulers])
                    optimizers, schedulers = optimizers_config
                    optimizer = optimizers[0] if isinstance(optimizers, list) else optimizers
                    scheduler = schedulers[0] if isinstance(schedulers, list) and schedulers else None
                elif isinstance(optimizers_config, list):
                    # è¿”å› [optimizer]
                    optimizer = optimizers_config[0]
                else:
                    # ç›´æ¥è¿”å› optimizer
                    optimizer = optimizers_config
                
                config = {}
                
                if optimizer:
                    # è·å–ä¼˜åŒ–å™¨ç±»å‹å’Œå‚æ•°
                    config['type'] = optimizer.__class__.__name__
                    
                    # è·å–å‚æ•°ç»„ï¼ˆåŒ…å«å­¦ä¹ ç‡ç­‰ï¼‰
                    if hasattr(optimizer, 'param_groups') and optimizer.param_groups:
                        param_group = optimizer.param_groups[0]
                        config['learning_rate'] = param_group.get('lr', 'N/A')
                        config['weight_decay'] = param_group.get('weight_decay', 0)
                        
                        # è·å–å…¶ä»–å¸¸è§å‚æ•°
                        if 'momentum' in param_group:
                            config['momentum'] = param_group['momentum']
                        if 'betas' in param_group:
                            config['betas'] = param_group['betas']
                        if 'eps' in param_group:
                            config['eps'] = param_group['eps']
                
                # è®°å½•å­¦ä¹ ç‡è°ƒåº¦å™¨
                if scheduler:
                    config['scheduler'] = {
                        'type': scheduler.__class__.__name__,
                    }
                    # è·å–è°ƒåº¦å™¨å‚æ•°
                    if hasattr(scheduler, 'T_max'):
                        config['scheduler']['T_max'] = scheduler.T_max
                    if hasattr(scheduler, 'gamma'):
                        config['scheduler']['gamma'] = scheduler.gamma
                    if hasattr(scheduler, 'step_size'):
                        config['scheduler']['step_size'] = scheduler.step_size
                
                return config
                
        except Exception as e:
            print(f"âš ï¸  è·å–ä¼˜åŒ–å™¨é…ç½®å¤±è´¥: {str(e)}")
            return None
    
    def _get_loss_function_info(self):
        """è·å–æŸå¤±å‡½æ•°ä¿¡æ¯"""
        try:
            loss_info = {}
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è‡ªå®šä¹‰æŸå¤±å‡½æ•°
            if hasattr(self.model, 'custom_mse_loss'):
                loss_info['type'] = 'Custom MSE Loss'
                loss_info['description'] = 'Custom MSE with NaN handling'
                loss_info['handles_nan'] = True
            elif hasattr(self.model, 'loss_fn'):
                loss_info['type'] = self.model.loss_fn.__class__.__name__
            else:
                # é»˜è®¤ MSE
                loss_info['type'] = 'MSE'
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æŸå¤±æƒé‡æˆ–å…¶ä»–é…ç½®
            if hasattr(self.model, 'loss_weight'):
                loss_info['weight'] = self.model.loss_weight
            
            return loss_info
            
        except Exception as e:
            print(f"âš ï¸  è·å–æŸå¤±å‡½æ•°ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None
    
    def _log_final_metrics(self, train_time, throughput):
        """è®°å½•æœ€ç»ˆè®­ç»ƒæŒ‡æ ‡"""
        try:
            final_metrics = {
                'train_time_seconds': train_time,
                'throughput_samples_per_second': throughput,
            }
            
            # è®°å½•æœ€ç»ˆçš„æŸå¤±å€¼
            if hasattr(self.model, 'train_loss') and self.model.train_loss:
                final_metrics['final_train_loss'] = self.model.train_loss[-1]
            
            if hasattr(self.model, 'val_loss') and self.model.val_loss:
                final_metrics['final_val_loss'] = self.model.val_loss[-1]
                # è®¡ç®—æœ€ä½³éªŒè¯æŸå¤±
                final_metrics['best_val_loss'] = min(self.model.val_loss)
            
            wandb.log(final_metrics)
            
        except Exception as e:
            print(f"âš ï¸  è®°å½•æœ€ç»ˆæŒ‡æ ‡å¤±è´¥: {str(e)}")
    
    def _save_model_artifact(self):
        """ä¿å­˜æ¨¡å‹åˆ° wandb artifacts"""
        try:
            # åˆ›å»º artifact
            artifact = wandb.Artifact(
                name=f"{self.title}_model",
                type='model',
                description=f"{self.model_class.__name__} trained on {self.area.title}",
                metadata={
                    'model_class': self.model_class.__name__,
                    'dataset_class': self.dataset_class.__name__,
                    'epochs': self.trainer_params.get('epochs', 100),
                    'batch_size': self.trainer_params.get('batch_size', 20),
                }
            )
            
            # æ·»åŠ æ¨¡å‹æ–‡ä»¶
            if self.save_path:
                artifact.add_file(self.save_path)
                wandb.log_artifact(artifact)
                print(f"\nâœ… æ¨¡å‹å·²ä¿å­˜åˆ° wandb artifacts: {artifact.name}")
            
        except Exception as e:
            print(f"\nâš ï¸  ä¿å­˜æ¨¡å‹åˆ° wandb å¤±è´¥: {str(e)}")
    
    def _print_optimization_summary(self, accumulate_grad_batches):
        """æ‰“å°ä¼˜åŒ–é…ç½®æ‘˜è¦"""
        is_windows = platform.system() == 'Windows'
        
        print("\n" + "="*60)
        print("ğŸš€ è®­ç»ƒä¼˜åŒ–é…ç½®")
        print("="*60)
        
        # ç³»ç»Ÿä¿¡æ¯
        if is_windows:
            print(f"\nğŸ’» ç³»ç»Ÿ: Windows (å¤šè¿›ç¨‹æ•°æ®åŠ è½½å·²ç¦ç”¨)")
        
        # Checkpoint ä¿¡æ¯
        if self.use_checkpoint:
            print(f"\nğŸ’¾ Checkpoint:")
            print(f"  â€¢ å¯ç”¨: True")
            if self.checkpoint_path and os.path.exists(self.checkpoint_path):
                print(f"  â€¢ æ¢å¤è‡ª: {self.checkpoint_path}")
            else:
                print(f"  â€¢ ä¿å­˜è·¯å¾„: out/checkpoints/{self.title}")
                print(f"  â€¢ ç›‘æ§æŒ‡æ ‡: {self.trainer_params.get('monitor', 'val_loss')}")
                print(f"  â€¢ ä¿å­˜æœ€ä¼˜: Top-{self.trainer_params.get('save_top_k', 3)}")
        
        # æ•°æ®åŠ è½½ä¼˜åŒ–
        print("\nğŸ“¦ æ•°æ®åŠ è½½:")
        num_workers = self.trainer_params.get('num_workers', 0 if is_windows else 8)
        print(f"  â€¢ num_workers: {num_workers}")
        if is_windows and num_workers == 0:
            print(f"    âš ï¸  Windowsç³»ç»Ÿé»˜è®¤ç¦ç”¨å¤šè¿›ç¨‹ï¼Œé¿å…å…¼å®¹æ€§é—®é¢˜")
        print(f"  â€¢ pin_memory: {self.trainer_params.get('pin_memory', True)}")
        print(f"  â€¢ persistent_workers: {self.trainer_params.get('persistent_workers', True) and num_workers > 0}")
        print(f"  â€¢ prefetch_factor: {self.trainer_params.get('prefetch_factor', 2 if num_workers > 0 else 'N/A')}")
        
        # è®­ç»ƒä¼˜åŒ–
        print("\nâš¡ è®­ç»ƒé…ç½®:")
        precision = self.trainer_params.get('precision', '16-mixed')
        print(f"  â€¢ precision: {precision}")
        if precision == '16-mixed':
            print(f"    âœ… æ··åˆç²¾åº¦è®­ç»ƒå·²å¯ç”¨ (FP16+FP32)")
        
        if torch.cuda.is_available():
            matmul_precision = self.trainer_params.get('matmul_precision', 'high')
            print(f"  â€¢ tensor_cores: {matmul_precision} precision")
            print(f"    âœ… Tensor Cores ä¼˜åŒ–å·²å¯ç”¨ (RTX GPU)")
        
        print(f"  â€¢ batch_size: {self.trainer_params.get('batch_size', 20)}")
        
        if accumulate_grad_batches > 1:
            effective_bs = self.trainer_params.get('batch_size', 20) * accumulate_grad_batches
            print(f"  â€¢ gradient_accumulation: {accumulate_grad_batches} (æœ‰æ•ˆbatch_size: {effective_bs})")
        
        if self.trainer_params.get('gradient_clip_val'):
            print(f"  â€¢ gradient_clipping: {self.trainer_params.get('gradient_clip_val')}")
        
        # æ¨¡å‹ç¼–è¯‘
        if self.trainer_params.get('compile_model', False):
            print(f"\nğŸ”§ æ¨¡å‹ç¼–è¯‘:")
            print(f"  â€¢ å·²å¯ç”¨: {self.trainer_params.get('compile_mode', 'default')} æ¨¡å¼")
        
        # Wandb
        if self.use_wandb:
            print(f"\nğŸ“Š Wandb æ—¥å¿—:")
            print(f"  â€¢ å·²å¯ç”¨: å®æ—¶è®°å½•è®­ç»ƒæŒ‡æ ‡")
        
        print("="*60 + "\n")

    def predict(self, offset: int, plot: bool = False) -> tuple:
        
        """
        é¢„æµ‹
        
        :param offset: æ•°æ®åç§»é‡
        :return: è¾“å…¥å’Œé¢„æµ‹è¾“å‡º
        """

        print(self.save_path)

        if not self.trained:
            self.model = load(self.save_path, weights_only=False)
            self.trained = True
            
        if not self.model:
            raise ValueError('æ— å·²è®­ç»ƒæ¨¡å‹')
        
        dataset_params = {
            **self.dataset_params,
            'offset': offset,
        }
        
        pred_dataset = self.dataset_class(
            lon=self.area.lon,
            lat=self.area.lat,
            **dataset_params
        )
        
        pred_loader = DataLoader(pred_dataset, batch_size=1, shuffle=False)
        
        input, output = next(iter(pred_loader))
        ssta = pred_dataset.read_ssta(offset)
        
        pred_output = self.model(input)
        
        input = input.detach().numpy()
        output = output.detach().numpy()
        pred_output = pred_output.detach().numpy()
        
        input = input[0, 0, 0, :, :]
        output = output[0, 0, :, :]
        pred_output = pred_output[0, 0, :, :]
        
        masked = np.isnan(output)
        pred_output[masked] = np.nan
        
        pred_diff = pred_output - output
        
        rmse = np.sqrt(np.nanmean((pred_diff) ** 2))
        r2 = 1 - np.nanmean((pred_diff) ** 2) / np.nanmean((output - np.nanmean(output)) ** 2)
        
        print(f"--------------------------------")
        
        print(f"Model: {self.model_class.__name__} Prediction RMSE: {rmse}")
        
        if plot:
            resolution = self.dataset_params.get('resolution', 1)
            plot_nino(ssta, step=resolution)
            plot_sst(pred_output, self.area.lon, self.area.lat, step=resolution)
            plot_sst_diff(pred_diff, self.area.lon, self.area.lat, step=resolution)
            
        return input, output, pred_output, rmse, r2, ssta
    

    def save(self):
        save(self.model, self.save_path)
